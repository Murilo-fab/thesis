{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e54dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from utils import get_parameters, prepare_loaders\n",
    "from train import train_downstream_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54919f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "INFERENCE_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training Parameters\n",
    "EPOCHS = 15\n",
    "WARMUP_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-2\n",
    "FINETUNE_LEARNING_RATE = 1e-4\n",
    "TRAINING_RATIOS = [0.1 , 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "DATASETS = [\"sim_city_6_miami_burglengenfeld\",\n",
    "            \"sim_city_6_miami_geldern\",\n",
    "            \"sim_city_6_miami_nauen\",\n",
    "            \"sim_city_6_miami_wittstock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cab5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lwm_model import lwm\n",
    "from downstream_models import RegressionHead\n",
    "\n",
    "class DownstreamWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper around:\n",
    "      - lwm (sequence model / encoder)\n",
    "      - RegressionHead (power / precoder regressor)\n",
    "\n",
    "    Output shape: (B, C, K, Nt)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_carriers: int,\n",
    "        n_users: int,\n",
    "        n_antennas: int,\n",
    "        d_model: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = lwm()\n",
    "        self.n_carriers = n_carriers\n",
    "        self.n_users = n_users\n",
    "        self.n_antennas = n_antennas\n",
    "\n",
    "        # infer d_model from encoder\n",
    "\n",
    "        self.regressor = RegressionHead(\n",
    "            d_model=d_model,\n",
    "            n_carriers=n_carriers,\n",
    "            n_users=n_users,\n",
    "            n_antennas=n_antennas,\n",
    "        )\n",
    "\n",
    "    def load_weights(self, path, device):\n",
    "        state_dict = torch.load(path, map_location=device)\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "        self.encoder.load_state_dict(new_state_dict)\n",
    "\n",
    "    def forward(self, channels, p_total):\n",
    "        \"\"\"\n",
    "        input_ids: (B, S)\n",
    "        masked_pos: optional (B, S')\n",
    "        returns:\n",
    "            power allocation: (B, C, K, Nt)\n",
    "        \"\"\"\n",
    "        B, S, K, N, _ = channels.shape\n",
    "\n",
    "        input_lwm = channels.reshape(B, S*K, 32)\n",
    "        embeddings, _ = self.encoder(input_lwm)\n",
    "\n",
    "        # features shape: (B, S, d_model)\n",
    "        \n",
    "        # Step 2: Regression head\n",
    "        power = self.regressor(embeddings, p_total)\n",
    "\n",
    "        # power shape: (B, C, K, Nt)\n",
    "        return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48acd371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:13<06:08, 33.46s/it, Train Loss=-440, Validation Loss=-436]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     38\u001b[39m opt_lwm = optim.Adam(trainable_params, lr=LEARNING_RATE)\n\u001b[32m     40\u001b[39m scheduler_lwm = ReduceLROnPlateau(opt_lwm, mode=\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.1\u001b[39m, patience=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mtrain_downstream_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_lwm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_TOTAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNOISE_VARIANCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfraction_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_lwm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_lwm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINFERENCE_DEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOGFILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/src/train.py:153\u001b[39m, in \u001b[36mtrain_downstream_model\u001b[39m\u001b[34m(model, p_total, noise_variance, train_loader, val_loader, optimizer, scheduler, epochs, device, log_file, save_dir)\u001b[39m\n\u001b[32m    150\u001b[39m     loss.backward()\n\u001b[32m    151\u001b[39m     optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m train_loss /= \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m    157\u001b[39m model.eval()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    # Parameters\n",
    "    parameters = get_parameters(f\"../data/{dataset}/parameters.txt\")\n",
    "    N_SAMPLES = parameters[\"samples\"]\n",
    "    USERS = parameters[\"users\"]\n",
    "    SUBCARRIERS = parameters[\"subcarriers\"]\n",
    "    BS_ATENNAS = parameters[\"bs_antennas\"]\n",
    "\n",
    "    P_TOTAL = parameters[\"p_total\"]\n",
    "    NOISE_VARIANCE = parameters[\"sigma2\"]\n",
    "\n",
    "    # Load data\n",
    "    channel_array = np.load(f\"../data/{dataset}/channels.npy\")\n",
    "    channel_array = np.stack((channel_array.real, channel_array.imag), axis=-1)\n",
    "    channel_tensor = torch.tensor(channel_array)\n",
    "\n",
    "    train_loader, val_loader, test_loader = prepare_loaders(channel_tensor, seed=SEED)\n",
    "\n",
    "    for training_ratio in TRAINING_RATIOS:\n",
    "        LOGFILE = f\"../data/{dataset}/train_lwm_{training_ratio}.csv\"\n",
    "\n",
    "        dataset = train_loader.dataset\n",
    "        n_samples = len(dataset)\n",
    "        n_subset = max(1, int(training_ratio * n_samples))\n",
    "\n",
    "        rng = np.random.default_rng(seed=SEED)\n",
    "        indices = rng.permutation(n_samples)[:n_subset]\n",
    "\n",
    "        subset = Subset(dataset, indices.tolist())\n",
    "        fraction_train_loader = DataLoader(subset, batch_size=train_loader.batch_size)\n",
    "\n",
    "        model = DownstreamWrapper(SUBCARRIERS, USERS, BS_ATENNAS, 128).to(INFERENCE_DEVICE)\n",
    "\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "        opt = optim.Adam(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, threshold=0.05)\n",
    "\n",
    "        train_downstream_model(model, P_TOTAL, NOISE_VARIANCE,\n",
    "                            fraction_train_loader, val_loader, opt, scheduler,\n",
    "                            EPOCHS, INFERENCE_DEVICE, LOGFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9a4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from downstream_models import RegressionHead\n",
    "\n",
    "class RawDataWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper around:\n",
    "      - RegressionHead (power / precoder regressor)\n",
    "\n",
    "    Output shape: (B, C, K, Nt)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_carriers: int,\n",
    "        n_users: int,\n",
    "        n_antennas: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_carriers = n_carriers\n",
    "        self.n_users = n_users\n",
    "        self.n_antennas = n_antennas\n",
    "\n",
    "        d_model = n_antennas * 2\n",
    "\n",
    "        self.regressor = RegressionHead(\n",
    "            d_model=d_model,\n",
    "            n_carriers=n_carriers,\n",
    "            n_users=n_users,\n",
    "            n_antennas=n_antennas,\n",
    "        )\n",
    "\n",
    "    def forward(self, channels, p_total):\n",
    "        \"\"\"\n",
    "        input_ids: (B, S)\n",
    "        returns:\n",
    "            power allocation: (B, C, K, Nt)\n",
    "        \"\"\"\n",
    "        B, S, K, N, _ = channels.shape\n",
    "\n",
    "        input = channels.reshape(B, S*K, -1)\n",
    "\n",
    "        power = self.regressor(input, p_total)\n",
    "\n",
    "        # power shape: (B, C, K, Nt)\n",
    "        return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ff841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.29s/it, Train Loss=-430, Validation Loss=-439]\n"
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    # Parameters\n",
    "    parameters = get_parameters(f\"../data/{dataset}/parameters.txt\")\n",
    "    N_SAMPLES = parameters[\"samples\"]\n",
    "    USERS = parameters[\"users\"]\n",
    "    SUBCARRIERS = parameters[\"subcarriers\"]\n",
    "    BS_ATENNAS = parameters[\"bs_antennas\"]\n",
    "\n",
    "    P_TOTAL = parameters[\"p_total\"]\n",
    "    NOISE_VARIANCE = parameters[\"sigma2\"]\n",
    "\n",
    "    # Load data\n",
    "    channel_array = np.load(f\"../data/{dataset}/channels.npy\")\n",
    "    channel_array = np.stack((channel_array.real, channel_array.imag), axis=-1)\n",
    "    channel_tensor = torch.tensor(channel_array)\n",
    "\n",
    "    train_loader, val_loader, test_loader = prepare_loaders(channel_tensor, seed=SEED)\n",
    "\n",
    "    for training_ratio in TRAINING_RATIOS:\n",
    "        LOGFILE = f\"../data/{dataset}/train_raw_{training_ratio}.csv\"\n",
    "\n",
    "        dataset = train_loader.dataset\n",
    "        n_samples = len(dataset)\n",
    "        n_subset = max(1, int(training_ratio * n_samples))\n",
    "\n",
    "        rng = np.random.default_rng(seed=SEED)\n",
    "        indices = rng.permutation(n_samples)[:n_subset]\n",
    "\n",
    "        subset = Subset(dataset, indices.tolist())\n",
    "        fraction_train_loader = DataLoader(subset, batch_size=train_loader.batch_size)\n",
    "\n",
    "        model = RawDataWrapper(SUBCARRIERS, USERS, BS_ATENNAS).to(INFERENCE_DEVICE)\n",
    "\n",
    "        opt = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, threshold=0.05)\n",
    "\n",
    "        train_downstream_model(model, P_TOTAL, NOISE_VARIANCE,\n",
    "                            fraction_train_loader, val_loader, opt, scheduler,\n",
    "                            EPOCHS, INFERENCE_DEVICE, LOGFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb07fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:41<00:00, 32.26s/it, Train Loss=-464, Validation Loss=-445]\n",
      " 20%|██        | 1/5 [00:56<03:44, 56.13s/it, Train Loss=-482, Validation Loss=-450]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m opt = optim.Adam(trainable_params, lr=FINETUNE_LEARNING_RATE)\n\u001b[32m     58\u001b[39m scheduler = ReduceLROnPlateau(opt, mode=\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.1\u001b[39m, patience=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mtrain_downstream_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_TOTAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNOISE_VARIANCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfraction_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mWARMUP_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINFERENCE_DEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOGFILE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/src/train.py:166\u001b[39m, in \u001b[36mtrain_downstream_model\u001b[39m\u001b[34m(model, p_total, noise_variance, train_loader, val_loader, optimizer, scheduler, epochs, device, log_file, save_dir)\u001b[39m\n\u001b[32m    163\u001b[39m         p_pred = model(batch_channels, p_total)\n\u001b[32m    165\u001b[39m         loss = sum_rate_loss(p_pred, batch_channels, noise_variance)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m         val_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m val_loss /= \u001b[38;5;28mlen\u001b[39m(val_loader)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "    # Parameters\n",
    "    parameters = get_parameters(f\"../data/{dataset}/parameters.txt\")\n",
    "    N_SAMPLES = parameters[\"samples\"]\n",
    "    USERS = parameters[\"users\"]\n",
    "    SUBCARRIERS = parameters[\"subcarriers\"]\n",
    "    BS_ATENNAS = parameters[\"bs_antennas\"]\n",
    "\n",
    "    P_TOTAL = parameters[\"p_total\"]\n",
    "    NOISE_VARIANCE = parameters[\"sigma2\"]\n",
    "\n",
    "    # Load data\n",
    "    channel_array = np.load(f\"../data/{dataset}/channels.npy\")\n",
    "    channel_array = np.stack((channel_array.real, channel_array.imag), axis=-1)\n",
    "    channel_tensor = torch.tensor(channel_array)\n",
    "\n",
    "    train_loader, val_loader, test_loader = prepare_loaders(channel_tensor, seed=SEED)\n",
    "\n",
    "    for training_ratio in TRAINING_RATIOS:\n",
    "        LOGFILE = f\"../data/{dataset}/train_lwm_finetune_9_11_{training_ratio}.csv\"\n",
    "\n",
    "        dataset = train_loader.dataset\n",
    "        n_samples = len(dataset)\n",
    "        n_subset = max(1, int(training_ratio * n_samples))\n",
    "\n",
    "        rng = np.random.default_rng(seed=SEED)\n",
    "        indices = rng.permutation(n_samples)[:n_subset]\n",
    "\n",
    "        subset = Subset(dataset, indices.tolist())\n",
    "        fraction_train_loader = DataLoader(subset, batch_size=train_loader.batch_size)\n",
    "\n",
    "        model = DownstreamWrapper(SUBCARRIERS, USERS, BS_ATENNAS, 128).to(INFERENCE_DEVICE)\n",
    "\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "        trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "        opt = optim.Adam(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, threshold=0.05)\n",
    "\n",
    "        train_downstream_model(model, P_TOTAL, NOISE_VARIANCE,\n",
    "                            fraction_train_loader, val_loader, opt, scheduler,\n",
    "                            WARMUP_EPOCHS, INFERENCE_DEVICE, LOGFILE)\n",
    "        \n",
    "        FINETUNE_EPOCHS = EPOCHS - WARMUP_EPOCHS\n",
    "\n",
    "        layers = [\"layers.9\", \"layers.10\", \"layers.11\"]\n",
    "\n",
    "        for name, param in model.encoder.named_parameters():\n",
    "            if any(layer in name for layer in layers):\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "        opt = optim.Adam(trainable_params, lr=FINETUNE_LEARNING_RATE)\n",
    "        scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, threshold=0.05)\n",
    "\n",
    "        train_downstream_model(model, P_TOTAL, NOISE_VARIANCE,\n",
    "                            fraction_train_loader, val_loader, opt, scheduler,\n",
    "                            FINETUNE_EPOCHS, INFERENCE_DEVICE, LOGFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    # Parameters\n",
    "    parameters = get_parameters(f\"../data/{dataset}/parameters.txt\")\n",
    "    N_SAMPLES = parameters[\"samples\"]\n",
    "    USERS = parameters[\"users\"]\n",
    "    SUBCARRIERS = parameters[\"subcarriers\"]\n",
    "    BS_ATENNAS = parameters[\"bs_antennas\"]\n",
    "\n",
    "    P_TOTAL = parameters[\"p_total\"]\n",
    "    NOISE_VARIANCE = parameters[\"sigma2\"]\n",
    "\n",
    "    # Load data\n",
    "    channel_array = np.load(f\"../data/{dataset}/channels.npy\")\n",
    "    channel_array = np.stack((channel_array.real, channel_array.imag), axis=-1)\n",
    "    channel_tensor = torch.tensor(channel_array)\n",
    "\n",
    "    train_loader, val_loader, test_loader = prepare_loaders(channel_tensor, seed=SEED)\n",
    "\n",
    "    for training_ratio in TRAINING_RATIOS:\n",
    "        LOGFILE = f\"../data/{dataset}/train_lwm_finetune_9_11_{training_ratio}.csv\"\n",
    "\n",
    "        dataset = train_loader.dataset\n",
    "        n_samples = len(dataset)\n",
    "        n_subset = max(1, int(training_ratio * n_samples))\n",
    "\n",
    "        rng = np.random.default_rng(seed=SEED)\n",
    "        indices = rng.permutation(n_samples)[:n_subset]\n",
    "\n",
    "        subset = Subset(dataset, indices.tolist())\n",
    "        fraction_train_loader = DataLoader(subset, batch_size=train_loader.batch_size)\n",
    "\n",
    "        model = DownstreamWrapper(SUBCARRIERS, USERS, BS_ATENNAS, 128).to(INFERENCE_DEVICE)\n",
    "\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "        opt = optim.Adam(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, threshold=0.05)\n",
    "\n",
    "        train_downstream_model(model, P_TOTAL, NOISE_VARIANCE,\n",
    "                            fraction_train_loader, val_loader, opt, scheduler,\n",
    "                            WARMUP_EPOCHS, INFERENCE_DEVICE, LOGFILE)\n",
    "        \n",
    "        FINETUNE_EPOCHS = EPOCHS - WARMUP_EPOCHS\n",
    "\n",
    "        for param in model.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "        opt = optim.Adam(trainable_params, lr=FINETUNE_LEARNING_RATE)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, threshold=0.05)\n",
    "\n",
    "        train_downstream_model(model, P_TOTAL, NOISE_VARIANCE,\n",
    "                            fraction_train_loader, val_loader, opt, scheduler,\n",
    "                            FINETUNE_EPOCHS, INFERENCE_DEVICE, LOGFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd6d91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "def compute_precoder_and_sumrate(\n",
    "    channels: torch.Tensor,\n",
    "    noise_variance: float,\n",
    "    p_total: float = 1.0,\n",
    "    method: str = \"mmse\",\n",
    "    reg_eps: float = 1e-6,\n",
    "    device: torch.device = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, float]:\n",
    "    \"\"\"\n",
    "    Compute linear precoders and sum-rate for multi-user MISO across carriers.\n",
    "\n",
    "    Args:\n",
    "        channels: Tensor of shape (C, K, Nt)  -- C carriers, K users, Nt transmit antennas.\n",
    "                  Each entry is the complex (or real) channel coefficient. If complex,\n",
    "                  channels should be a complex dtype tensor (torch.complex64/128).\n",
    "        noise_variance: scalar noise variance (sigma^2) at each user receiver.\n",
    "        p_total: total transmit power per carrier (scalar). The precoder is scaled so\n",
    "                 that trace(W W^H) == p_total for each carrier.\n",
    "        method: \"zf\" or \"mmse\" (regularized ZF). Default \"mmse\".\n",
    "        reg_eps: small regularizer for numerical stability.\n",
    "        device: torch device or None (will use channels.device if None).\n",
    "\n",
    "    Returns:\n",
    "        precoders: Tensor of shape (C, Nt, K) containing precoder for each carrier.\n",
    "                   For carrier c, W_c is (Nt x K) matrix mapping K streams to Nt antennas.\n",
    "        rates_per_carrier: Tensor of shape (C,) sum-rate per carrier (in bits/s/Hz).\n",
    "        total_sum_rate: scalar = sum over carriers of rates_per_carrier.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = channels.device\n",
    "\n",
    "    assert channels.ndim == 3, \"channels must be shape (C, K, Nt)\"\n",
    "    C, K, Nt = channels.shape\n",
    "    dtype = channels.dtype\n",
    "\n",
    "    precoders = torch.zeros((C, Nt, K), dtype=dtype, device=device)\n",
    "    rates = torch.zeros(C, dtype=dtype, device=device)\n",
    "\n",
    "    # Loop over carriers (vectorizing is possible but loop is clearer)\n",
    "    for c in range(C):\n",
    "        # H : (K x Nt)\n",
    "        H = channels[c]  # shape (K, Nt)\n",
    "\n",
    "        # For math convenience, convert to complex-compatible operations if necessary:\n",
    "        # We assume H is of dtype float or complex; torch handles both.\n",
    "        # Compute Gram = H @ H^H  -> (K x K)\n",
    "        # Note: For complex, use conjugate transpose\n",
    "        if torch.is_complex(H):\n",
    "            Gram = H @ H.conj().transpose(-1, -2)  # (K x K)\n",
    "        else:\n",
    "            Gram = H @ H.transpose(-1, -2)\n",
    "\n",
    "        # Regularization parameter for MMSE. A standard heuristic:\n",
    "        # reg = (noise_variance / p_total) * trace(Gram) / K\n",
    "        # We'll use a simple scalar reg scaled by the average eigenvalue:\n",
    "        avg_eig = (Gram.diag().real if torch.is_complex(Gram) else Gram.diag()).mean()\n",
    "        reg = (noise_variance / (p_total + 1e-12)) * (avg_eig.real if torch.is_complex(avg_eig) else avg_eig)\n",
    "        reg = reg.clamp(min=reg_eps)\n",
    "\n",
    "        if method.lower() == \"zf\":\n",
    "            # Standard ZF: W = H^H (H H^H)^{-1}\n",
    "            # If Gram is singular, add tiny epsilon\n",
    "            try:\n",
    "                inv = torch.linalg.inv(Gram + reg_eps * torch.eye(K, dtype=dtype, device=device))\n",
    "            except RuntimeError:\n",
    "                inv = torch.pinverse(Gram + reg_eps * torch.eye(K, dtype=dtype, device=device))\n",
    "            if torch.is_complex(H):\n",
    "                W = H.conj().transpose(-1, -2) @ inv  # (Nt x K)\n",
    "            else:\n",
    "                W = H.transpose(-1, -2) @ inv\n",
    "        else:\n",
    "            # MMSE / regularized ZF: W = H^H (H H^H + alpha I)^{-1}\n",
    "            alpha = reg  # scalar\n",
    "            try:\n",
    "                inv = torch.linalg.inv(Gram + alpha * torch.eye(K, dtype=dtype, device=device))\n",
    "            except RuntimeError:\n",
    "                inv = torch.pinverse(Gram + alpha * torch.eye(K, dtype=dtype, device=device))\n",
    "            if torch.is_complex(H):\n",
    "                W = H.conj().transpose(-1, -2) @ inv  # (Nt x K)\n",
    "            else:\n",
    "                W = H.transpose(-1, -2) @ inv  # (Nt x K)\n",
    "\n",
    "        # Normalize W to satisfy total transmit power p_total:\n",
    "        # current power = trace(W W^H) = sum of squared magnitudes of all entries\n",
    "        if torch.is_complex(W):\n",
    "            current_power = torch.real(torch.trace(W @ W.conj().transpose(-1, -2)))\n",
    "        else:\n",
    "            current_power = torch.trace(W @ W.transpose(-1, -2))\n",
    "\n",
    "        # If current_power == 0 (rare), skip scaling to avoid div0\n",
    "        if current_power <= 0:\n",
    "            scale = 0.0\n",
    "        else:\n",
    "            scale = math.sqrt(float(p_total) / float(current_power))\n",
    "\n",
    "        W = W * scale\n",
    "        precoders[c] = W\n",
    "\n",
    "        # Compute per-user SINRs and sum-rate for this carrier\n",
    "        # For user k: h_k is row k of H (1 x Nt), w_j is column j of W (Nt x 1)\n",
    "        # signal_power_k = |h_k w_k|^2\n",
    "        # interference_k = sum_{j != k} |h_k w_j|^2\n",
    "        # noise = noise_variance\n",
    "        # SINR_k = signal_power_k / (interference_k + noise_variance)\n",
    "\n",
    "        # Compute full received covariance: Y = H W  -> (K x K) -> element (k,j) = h_k w_j (complex or real)\n",
    "        HW = H @ W  # shape (K x K)\n",
    "        # elementwise magnitude squared\n",
    "        if torch.is_complex(HW):\n",
    "            mag2 = (HW.abs() ** 2)  # (K x K)\n",
    "        else:\n",
    "            mag2 = (HW ** 2)\n",
    "\n",
    "        # signal powers are diagonal entries mag2[k,k]\n",
    "        signal_powers = mag2.diag()  # (K,)\n",
    "        interference_powers = mag2.sum(dim=1) - signal_powers  # sum over j != k\n",
    "\n",
    "        sinrs = signal_powers / (interference_powers + noise_variance + 1e-12)\n",
    "\n",
    "        # rates in bits/s/Hz: log2(1 + SINR)\n",
    "        rates_c = torch.log2(1.0 + sinrs)\n",
    "        rates[c] = rates_c.sum().real if torch.is_complex(rates_c) else rates_c.sum()\n",
    "\n",
    "    total_sum_rate = float(rates.sum())\n",
    "    return precoders, rates, total_sum_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eff0aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sum-rate: 698.6423065185547\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "def precoder_and_sumrate_batch_realimag(\n",
    "    dataloader,\n",
    "    noise_variance: float,\n",
    "    p_total: float = 1.0,\n",
    "    method: str = \"mmse\",\n",
    "    reg_eps: float = 1e-6,\n",
    "    device: torch.device = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute average sum-rate over dataset when channels are given as (B, C, K, Nt, 2).\n",
    "\n",
    "    Format:\n",
    "        channels[..., 0] = real part\n",
    "        channels[..., 1] = imaginary part\n",
    "\n",
    "    Returns:\n",
    "        avg_sum_rate (float)\n",
    "    \"\"\"\n",
    "\n",
    "    total_rate = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Extract channels\n",
    "        if isinstance(batch, (tuple, list)):\n",
    "            channels_ri = batch[0]\n",
    "        else:\n",
    "            channels_ri = batch\n",
    "\n",
    "        if device is not None:\n",
    "            channels_ri = channels_ri.to(device)\n",
    "\n",
    "        # Convert (B,C,K,Nt,2) → complex tensor (B,C,K,Nt)\n",
    "        channels = torch.complex(channels_ri[..., 0], channels_ri[..., 1])\n",
    "\n",
    "        B, C, K, Nt = channels.shape\n",
    "\n",
    "        for b in range(B):\n",
    "            H = channels[b]   # (C, K, Nt)\n",
    "\n",
    "            _, _, sample_sum_rate = compute_precoder_and_sumrate(\n",
    "                H,\n",
    "                noise_variance=noise_variance,\n",
    "                p_total=p_total,\n",
    "                method=method,\n",
    "                reg_eps=reg_eps,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            total_rate += sample_sum_rate\n",
    "\n",
    "        total_samples += B\n",
    "\n",
    "    avg_sum_rate = total_rate / total_samples\n",
    "    return avg_sum_rate\n",
    "\n",
    "avg_rate = precoder_and_sumrate_batch_realimag(\n",
    "    dataloader=val_loader,\n",
    "    noise_variance=NOISE_VARIANCE,\n",
    "    p_total=P_TOTAL,\n",
    "    method=\"mmse\",\n",
    "    device=INFERENCE_DEVICE\n",
    ")\n",
    "\n",
    "print(\"Average sum-rate:\", avg_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
