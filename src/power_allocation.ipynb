{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e54dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from utils import get_parameters, prepare_loaders\n",
    "from train import train_downstream_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54919f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "DATASET = \"sim_city_6_miami_jülich\"\n",
    "\n",
    "parameters = get_parameters(f\"../data/{DATASET}/parameters.txt\")\n",
    "N_SAMPLES = parameters[\"samples\"]\n",
    "USERS = parameters[\"users\"]\n",
    "SUBCARRIERS = parameters[\"subcarriers\"]\n",
    "BS_ATENNAS = parameters[\"bs_antennas\"]\n",
    "\n",
    "P_TOTAL = parameters[\"p_total\"]\n",
    "NOISE_VARIANCE = parameters[\"sigma2\"]\n",
    "\n",
    "# Load data\n",
    "channel_array = np.load(f\"../data/{DATASET}/channels.npy\")\n",
    "channel_array = np.stack((channel_array.real, channel_array.imag), axis=-1)\n",
    "channel_tensor = torch.tensor(channel_array)\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_loaders(channel_tensor)\n",
    "\n",
    "INFERENCE_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cab5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lwm_model import lwm\n",
    "from downstream_models import RegressionHead\n",
    "\n",
    "class DownstreamWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper around:\n",
    "      - lwm (sequence model / encoder)\n",
    "      - RegressionHead (power / precoder regressor)\n",
    "\n",
    "    Output shape: (B, C, K, Nt)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_carriers: int,\n",
    "        n_users: int,\n",
    "        n_antennas: int,\n",
    "        d_model: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = lwm()\n",
    "        self.n_carriers = n_carriers\n",
    "        self.n_users = n_users\n",
    "        self.n_antennas = n_antennas\n",
    "\n",
    "        # infer d_model from encoder\n",
    "\n",
    "        self.regressor = RegressionHead(\n",
    "            d_model=d_model,\n",
    "            n_carriers=n_carriers,\n",
    "            n_users=n_users,\n",
    "            n_antennas=n_antennas,\n",
    "        )\n",
    "\n",
    "    def load_weights(self, path, device):\n",
    "        state_dict = torch.load(path, map_location=device)\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "        self.encoder.load_state_dict(new_state_dict)\n",
    "\n",
    "    def forward(self, channels, p_total):\n",
    "        \"\"\"\n",
    "        input_ids: (B, S)\n",
    "        masked_pos: optional (B, S')\n",
    "        returns:\n",
    "            power allocation: (B, C, K, Nt)\n",
    "        \"\"\"\n",
    "        B, S, N, K, _ = channels.shape\n",
    "\n",
    "        input_lwm = channels.reshape(B, S, -1)\n",
    "        embeddings, _ = self.encoder(input_lwm)\n",
    "\n",
    "        # features shape: (B, S, d_model)\n",
    "        \n",
    "        # Step 2: Regression head\n",
    "        power = self.regressor(embeddings, p_total)\n",
    "\n",
    "        # power shape: (B, C, K, Nt)\n",
    "        return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48acd371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  2.06it/s, Train Loss=-379, Validation Loss=-400]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.38it/s, Train Loss=-430, Validation Loss=-419]\n",
      "100%|██████████| 15/15 [00:03<00:00,  3.89it/s, Train Loss=-416, Validation Loss=-418]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.42it/s, Train Loss=-421, Validation Loss=-419]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.99it/s, Train Loss=-409, Validation Loss=-426]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.65it/s, Train Loss=-412, Validation Loss=-426]\n",
      "100%|██████████| 15/15 [00:06<00:00,  2.34it/s, Train Loss=-435, Validation Loss=-426]\n",
      "100%|██████████| 15/15 [00:07<00:00,  2.08it/s, Train Loss=-397, Validation Loss=-427]\n",
      "100%|██████████| 15/15 [00:07<00:00,  1.92it/s, Train Loss=-416, Validation Loss=-419]\n",
      "100%|██████████| 15/15 [00:08<00:00,  1.78it/s, Train Loss=-420, Validation Loss=-426]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-2\n",
    "TRAINING_RATIOS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for training_ratio in TRAINING_RATIOS:\n",
    "    LOGFILE = f\"../data/{DATASET}/train_lwm_{training_ratio}.csv\"\n",
    "\n",
    "    dataset = train_loader.dataset\n",
    "    n_subset = max(1, int(training_ratio * len(dataset)))\n",
    "    indices = list(range(len(dataset)))\n",
    "    indices = indices = np.random.permutation(indices)\n",
    "    subset_indices = indices[:n_subset].tolist()\n",
    "    subset = Subset(dataset, subset_indices)\n",
    "\n",
    "    fraction_train_loader = DataLoader(subset, batch_size=train_loader.batch_size)\n",
    "\n",
    "    model_lwm = DownstreamWrapper(SUBCARRIERS, USERS, BS_ATENNAS, 128).to(INFERENCE_DEVICE)\n",
    "\n",
    "    for param in model_lwm.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model_lwm.parameters())\n",
    "    opt_lwm = optim.Adam(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "    scheduler_lwm = ReduceLROnPlateau(opt_lwm, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    train_downstream_model(model_lwm, P_TOTAL, NOISE_VARIANCE,\n",
    "                           fraction_train_loader, val_loader, opt_lwm, scheduler_lwm,\n",
    "                           EPOCHS, INFERENCE_DEVICE, LOGFILE)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b9a4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from downstream_models import RegressionHead\n",
    "\n",
    "class RawDataWrapper(nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper around:\n",
    "      - RegressionHead (power / precoder regressor)\n",
    "\n",
    "    Output shape: (B, C, K, Nt)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_carriers: int,\n",
    "        n_users: int,\n",
    "        n_antennas: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_carriers = n_carriers\n",
    "        self.n_users = n_users\n",
    "        self.n_antennas = n_antennas\n",
    "\n",
    "        d_model = n_antennas * n_users * 2\n",
    "\n",
    "        self.regressor = RegressionHead(\n",
    "            d_model=d_model,\n",
    "            n_carriers=n_carriers,\n",
    "            n_users=n_users,\n",
    "            n_antennas=n_antennas,\n",
    "        )\n",
    "\n",
    "    def forward(self, channels, p_total):\n",
    "        \"\"\"\n",
    "        input_ids: (B, S)\n",
    "        returns:\n",
    "            power allocation: (B, C, K, Nt)\n",
    "        \"\"\"\n",
    "        B, S, N, K, _ = channels.shape\n",
    "\n",
    "        input = channels.reshape(B, S, -1)\n",
    "\n",
    "        power = self.regressor(input, p_total)\n",
    "\n",
    "        # power shape: (B, C, K, Nt)\n",
    "        return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "562ff841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 35.43it/s, Train Loss=-271, Validation Loss=-376]\n",
      "100%|██████████| 15/15 [00:00<00:00, 30.10it/s, Train Loss=-409, Validation Loss=-421]\n",
      "100%|██████████| 15/15 [00:00<00:00, 22.35it/s, Train Loss=-401, Validation Loss=-424]\n",
      "100%|██████████| 15/15 [00:00<00:00, 20.64it/s, Train Loss=-429, Validation Loss=-404]\n",
      "100%|██████████| 15/15 [00:00<00:00, 17.67it/s, Train Loss=-416, Validation Loss=-427]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.73it/s, Train Loss=-413, Validation Loss=-425]\n",
      "100%|██████████| 15/15 [00:01<00:00, 14.43it/s, Train Loss=-414, Validation Loss=-423]\n",
      "100%|██████████| 15/15 [00:01<00:00, 13.11it/s, Train Loss=-419, Validation Loss=-418]\n",
      "100%|██████████| 15/15 [00:01<00:00, 12.00it/s, Train Loss=-421, Validation Loss=-425]\n",
      "100%|██████████| 15/15 [00:01<00:00, 11.17it/s, Train Loss=-416, Validation Loss=-427]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-2\n",
    "TRAINING_RATIOS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "for training_ratio in TRAINING_RATIOS:\n",
    "    LOGFILE = f\"../data/{DATASET}/train_raw_{training_ratio}.csv\"\n",
    "\n",
    "    dataset = train_loader.dataset\n",
    "    n_subset = max(1, int(training_ratio * len(dataset)))\n",
    "    indices = list(range(len(dataset)))\n",
    "    indices = indices = np.random.permutation(indices)\n",
    "    subset_indices = indices[:n_subset].tolist()\n",
    "    subset = Subset(dataset, subset_indices)\n",
    "\n",
    "    fraction_train_loader = DataLoader(subset, batch_size=train_loader.batch_size)\n",
    "\n",
    "    model_raw = RawDataWrapper(SUBCARRIERS, USERS, BS_ATENNAS).to(INFERENCE_DEVICE)\n",
    "\n",
    "    opt_raw = optim.Adam(model_raw.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    scheduler_raw = ReduceLROnPlateau(opt_lwm, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "    train_downstream_model(model_raw, P_TOTAL, NOISE_VARIANCE,\n",
    "                           fraction_train_loader, val_loader, opt_raw, scheduler_raw,\n",
    "                           EPOCHS, INFERENCE_DEVICE, LOGFILE)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd6d91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "def compute_precoder_and_sumrate(\n",
    "    channels: torch.Tensor,\n",
    "    noise_variance: float,\n",
    "    p_total: float = 1.0,\n",
    "    method: str = \"mmse\",\n",
    "    reg_eps: float = 1e-6,\n",
    "    device: torch.device = None,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, float]:\n",
    "    \"\"\"\n",
    "    Compute linear precoders and sum-rate for multi-user MISO across carriers.\n",
    "\n",
    "    Args:\n",
    "        channels: Tensor of shape (C, K, Nt)  -- C carriers, K users, Nt transmit antennas.\n",
    "                  Each entry is the complex (or real) channel coefficient. If complex,\n",
    "                  channels should be a complex dtype tensor (torch.complex64/128).\n",
    "        noise_variance: scalar noise variance (sigma^2) at each user receiver.\n",
    "        p_total: total transmit power per carrier (scalar). The precoder is scaled so\n",
    "                 that trace(W W^H) == p_total for each carrier.\n",
    "        method: \"zf\" or \"mmse\" (regularized ZF). Default \"mmse\".\n",
    "        reg_eps: small regularizer for numerical stability.\n",
    "        device: torch device or None (will use channels.device if None).\n",
    "\n",
    "    Returns:\n",
    "        precoders: Tensor of shape (C, Nt, K) containing precoder for each carrier.\n",
    "                   For carrier c, W_c is (Nt x K) matrix mapping K streams to Nt antennas.\n",
    "        rates_per_carrier: Tensor of shape (C,) sum-rate per carrier (in bits/s/Hz).\n",
    "        total_sum_rate: scalar = sum over carriers of rates_per_carrier.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = channels.device\n",
    "\n",
    "    assert channels.ndim == 3, \"channels must be shape (C, K, Nt)\"\n",
    "    C, K, Nt = channels.shape\n",
    "    dtype = channels.dtype\n",
    "\n",
    "    precoders = torch.zeros((C, Nt, K), dtype=dtype, device=device)\n",
    "    rates = torch.zeros(C, dtype=dtype, device=device)\n",
    "\n",
    "    # Loop over carriers (vectorizing is possible but loop is clearer)\n",
    "    for c in range(C):\n",
    "        # H : (K x Nt)\n",
    "        H = channels[c]  # shape (K, Nt)\n",
    "\n",
    "        # For math convenience, convert to complex-compatible operations if necessary:\n",
    "        # We assume H is of dtype float or complex; torch handles both.\n",
    "        # Compute Gram = H @ H^H  -> (K x K)\n",
    "        # Note: For complex, use conjugate transpose\n",
    "        if torch.is_complex(H):\n",
    "            Gram = H @ H.conj().transpose(-1, -2)  # (K x K)\n",
    "        else:\n",
    "            Gram = H @ H.transpose(-1, -2)\n",
    "\n",
    "        # Regularization parameter for MMSE. A standard heuristic:\n",
    "        # reg = (noise_variance / p_total) * trace(Gram) / K\n",
    "        # We'll use a simple scalar reg scaled by the average eigenvalue:\n",
    "        avg_eig = (Gram.diag().real if torch.is_complex(Gram) else Gram.diag()).mean()\n",
    "        reg = (noise_variance / (p_total + 1e-12)) * (avg_eig.real if torch.is_complex(avg_eig) else avg_eig)\n",
    "        reg = reg.clamp(min=reg_eps)\n",
    "\n",
    "        if method.lower() == \"zf\":\n",
    "            # Standard ZF: W = H^H (H H^H)^{-1}\n",
    "            # If Gram is singular, add tiny epsilon\n",
    "            try:\n",
    "                inv = torch.linalg.inv(Gram + reg_eps * torch.eye(K, dtype=dtype, device=device))\n",
    "            except RuntimeError:\n",
    "                inv = torch.pinverse(Gram + reg_eps * torch.eye(K, dtype=dtype, device=device))\n",
    "            if torch.is_complex(H):\n",
    "                W = H.conj().transpose(-1, -2) @ inv  # (Nt x K)\n",
    "            else:\n",
    "                W = H.transpose(-1, -2) @ inv\n",
    "        else:\n",
    "            # MMSE / regularized ZF: W = H^H (H H^H + alpha I)^{-1}\n",
    "            alpha = reg  # scalar\n",
    "            try:\n",
    "                inv = torch.linalg.inv(Gram + alpha * torch.eye(K, dtype=dtype, device=device))\n",
    "            except RuntimeError:\n",
    "                inv = torch.pinverse(Gram + alpha * torch.eye(K, dtype=dtype, device=device))\n",
    "            if torch.is_complex(H):\n",
    "                W = H.conj().transpose(-1, -2) @ inv  # (Nt x K)\n",
    "            else:\n",
    "                W = H.transpose(-1, -2) @ inv  # (Nt x K)\n",
    "\n",
    "        # Normalize W to satisfy total transmit power p_total:\n",
    "        # current power = trace(W W^H) = sum of squared magnitudes of all entries\n",
    "        if torch.is_complex(W):\n",
    "            current_power = torch.real(torch.trace(W @ W.conj().transpose(-1, -2)))\n",
    "        else:\n",
    "            current_power = torch.trace(W @ W.transpose(-1, -2))\n",
    "\n",
    "        # If current_power == 0 (rare), skip scaling to avoid div0\n",
    "        if current_power <= 0:\n",
    "            scale = 0.0\n",
    "        else:\n",
    "            scale = math.sqrt(float(p_total) / float(current_power))\n",
    "\n",
    "        W = W * scale\n",
    "        precoders[c] = W\n",
    "\n",
    "        # Compute per-user SINRs and sum-rate for this carrier\n",
    "        # For user k: h_k is row k of H (1 x Nt), w_j is column j of W (Nt x 1)\n",
    "        # signal_power_k = |h_k w_k|^2\n",
    "        # interference_k = sum_{j != k} |h_k w_j|^2\n",
    "        # noise = noise_variance\n",
    "        # SINR_k = signal_power_k / (interference_k + noise_variance)\n",
    "\n",
    "        # Compute full received covariance: Y = H W  -> (K x K) -> element (k,j) = h_k w_j (complex or real)\n",
    "        HW = H @ W  # shape (K x K)\n",
    "        # elementwise magnitude squared\n",
    "        if torch.is_complex(HW):\n",
    "            mag2 = (HW.abs() ** 2)  # (K x K)\n",
    "        else:\n",
    "            mag2 = (HW ** 2)\n",
    "\n",
    "        # signal powers are diagonal entries mag2[k,k]\n",
    "        signal_powers = mag2.diag()  # (K,)\n",
    "        interference_powers = mag2.sum(dim=1) - signal_powers  # sum over j != k\n",
    "\n",
    "        sinrs = signal_powers / (interference_powers + noise_variance + 1e-12)\n",
    "\n",
    "        # rates in bits/s/Hz: log2(1 + SINR)\n",
    "        rates_c = torch.log2(1.0 + sinrs)\n",
    "        rates[c] = rates_c.sum().real if torch.is_complex(rates_c) else rates_c.sum()\n",
    "\n",
    "    total_sum_rate = float(rates.sum())\n",
    "    return precoders, rates, total_sum_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eff0aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sum-rate: 698.6423065185547\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "def precoder_and_sumrate_batch_realimag(\n",
    "    dataloader,\n",
    "    noise_variance: float,\n",
    "    p_total: float = 1.0,\n",
    "    method: str = \"mmse\",\n",
    "    reg_eps: float = 1e-6,\n",
    "    device: torch.device = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute average sum-rate over dataset when channels are given as (B, C, K, Nt, 2).\n",
    "\n",
    "    Format:\n",
    "        channels[..., 0] = real part\n",
    "        channels[..., 1] = imaginary part\n",
    "\n",
    "    Returns:\n",
    "        avg_sum_rate (float)\n",
    "    \"\"\"\n",
    "\n",
    "    total_rate = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Extract channels\n",
    "        if isinstance(batch, (tuple, list)):\n",
    "            channels_ri = batch[0]\n",
    "        else:\n",
    "            channels_ri = batch\n",
    "\n",
    "        if device is not None:\n",
    "            channels_ri = channels_ri.to(device)\n",
    "\n",
    "        # Convert (B,C,K,Nt,2) → complex tensor (B,C,K,Nt)\n",
    "        channels = torch.complex(channels_ri[..., 0], channels_ri[..., 1])\n",
    "\n",
    "        B, C, K, Nt = channels.shape\n",
    "\n",
    "        for b in range(B):\n",
    "            H = channels[b]   # (C, K, Nt)\n",
    "\n",
    "            _, _, sample_sum_rate = compute_precoder_and_sumrate(\n",
    "                H,\n",
    "                noise_variance=noise_variance,\n",
    "                p_total=p_total,\n",
    "                method=method,\n",
    "                reg_eps=reg_eps,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            total_rate += sample_sum_rate\n",
    "\n",
    "        total_samples += B\n",
    "\n",
    "    avg_sum_rate = total_rate / total_samples\n",
    "    return avg_sum_rate\n",
    "\n",
    "avg_rate = precoder_and_sumrate_batch_realimag(\n",
    "    dataloader=val_loader,\n",
    "    noise_variance=NOISE_VARIANCE,\n",
    "    p_total=P_TOTAL,\n",
    "    method=\"mmse\",\n",
    "    device=INFERENCE_DEVICE\n",
    ")\n",
    "\n",
    "print(\"Average sum-rate:\", avg_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
