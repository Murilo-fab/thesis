{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e42d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.data_classes import ModelConfig, TaskConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945ffa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Task: LoS_NLoS_Classification\n",
      "Results will be saved to: ../results/LoS_NLoS_Classification/city_6_miami/2026-02-04_12-53-16\n",
      "\n",
      "Generating dataset for city_6_miami...\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 42984/42984 [00:00<00:00, 164938.46it/s]\n",
      "Generating channels: 100%|██████████| 42984/42984 [00:03<00:00, 14272.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10441 samples. Final Shape: torch.Size([10441, 32, 32])\n",
      "Training model: Raw\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.5936\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.7603\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9173\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9693\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9770\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9770\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9866\n",
      "\tMFLOPs: 1.215362 | Params_M: 1.215362 | Encoder Latency: 0.0097 | Head Latency: 0.2485\n",
      "\tSNR -20 | Final F1: 0.9511\n",
      "\tSNR -15 | Final F1: 0.9799\n",
      "\tSNR -10 | Final F1: 0.9856\n",
      "\tSNR -5 | Final F1: 0.9861\n",
      "\tSNR 0 | Final F1: 0.9890\n",
      "\tSNR 5 | Final F1: 0.9866\n",
      "\tSNR 10 | Final F1: 0.9866\n",
      "\tSNR 15 | Final F1: 0.9866\n",
      "\tSNR 20 | Final F1: 0.9866\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: Enhanced Raw\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.9087\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.9143\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9296\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9521\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9722\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9722\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9875\n",
      "\tMFLOPs: 1.215362 | Params_M: 1.215362 | Encoder Latency: 0.0118 | Head Latency: 0.2655\n",
      "\tSNR -20 | Final F1: 0.7971\n",
      "\tSNR -15 | Final F1: 0.9064\n",
      "\tSNR -10 | Final F1: 0.9296\n",
      "\tSNR -5 | Final F1: 0.8853\n",
      "\tSNR 0 | Final F1: 0.8747\n",
      "\tSNR 5 | Final F1: 0.9679\n",
      "\tSNR 10 | Final F1: 0.9871\n",
      "\tSNR 15 | Final F1: 0.9880\n",
      "\tSNR 20 | Final F1: 0.9880\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: AE - 1/16\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.8558\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.9401\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9765\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9804\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9847\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9828\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9914\n",
      "\tMFLOPs: 59.248134 | Params_M: 2.673608 | Encoder Latency: 0.9600 | Head Latency: 0.1342\n",
      "\tSNR -20 | Final F1: 0.9368\n",
      "\tSNR -15 | Final F1: 0.9415\n",
      "\tSNR -10 | Final F1: 0.9679\n",
      "\tSNR -5 | Final F1: 0.9856\n",
      "\tSNR 0 | Final F1: 0.9899\n",
      "\tSNR 5 | Final F1: 0.9904\n",
      "\tSNR 10 | Final F1: 0.9899\n",
      "\tSNR 15 | Final F1: 0.9914\n",
      "\tSNR 20 | Final F1: 0.9914\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: AE - 1/32\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.9102\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.8899\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9531\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9722\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9818\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9852\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9919\n",
      "\tMFLOPs: 58.691014 | Params_M: 1.5922 | Encoder Latency: 0.8844 | Head Latency: 0.1302\n",
      "\tSNR -20 | Final F1: 0.9435\n",
      "\tSNR -15 | Final F1: 0.9348\n",
      "\tSNR -10 | Final F1: 0.9698\n",
      "\tSNR -5 | Final F1: 0.9871\n",
      "\tSNR 0 | Final F1: 0.9904\n",
      "\tSNR 5 | Final F1: 0.9919\n",
      "\tSNR 10 | Final F1: 0.9914\n",
      "\tSNR 15 | Final F1: 0.9914\n",
      "\tSNR 20 | Final F1: 0.9919\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: LWM - CLS\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.3510\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.9424\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9505\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9202\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9756\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9458\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9741\n",
      "\tMFLOPs: 6.881026 | Params_M: 2.702626 | Encoder Latency: 13.9825 | Head Latency: 0.1973\n",
      "\tSNR -20 | Final F1: 0.5400\n",
      "\tSNR -15 | Final F1: 0.6952\n",
      "\tSNR -10 | Final F1: 0.8107\n",
      "\tSNR -5 | Final F1: 0.8985\n",
      "\tSNR 0 | Final F1: 0.9419\n",
      "\tSNR 5 | Final F1: 0.9559\n",
      "\tSNR 10 | Final F1: 0.9665\n",
      "\tSNR 15 | Final F1: 0.9698\n",
      "\tSNR 20 | Final F1: 0.9703\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: LWM - CLS (Partial Fine-Tuning)\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.3510\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.9703\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9770\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9789\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9765\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9746\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9976\n",
      "\tMFLOPs: 6.881026 | Params_M: 2.702626 | Encoder Latency: 13.3078 | Head Latency: 0.1951\n",
      "\tSNR -20 | Final F1: 0.7590\n",
      "\tSNR -15 | Final F1: 0.8642\n",
      "\tSNR -10 | Final F1: 0.9270\n",
      "\tSNR -5 | Final F1: 0.9310\n",
      "\tSNR 0 | Final F1: 0.9483\n",
      "\tSNR 5 | Final F1: 0.9818\n",
      "\tSNR 10 | Final F1: 0.9856\n",
      "\tSNR 15 | Final F1: 0.9919\n",
      "\tSNR 20 | Final F1: 0.9952\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: LWM - CLS (Full Fine-Tuning)\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.3510\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.9525\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9544\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9761\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9713\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9856\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9736\n",
      "\tMFLOPs: 6.881026 | Params_M: 2.702626 | Encoder Latency: 14.2974 | Head Latency: 0.1975\n",
      "\tSNR -20 | Final F1: 0.6114\n",
      "\tSNR -15 | Final F1: 0.7446\n",
      "\tSNR -10 | Final F1: 0.8243\n",
      "\tSNR -5 | Final F1: 0.8728\n",
      "\tSNR 0 | Final F1: 0.9209\n",
      "\tSNR 5 | Final F1: 0.9452\n",
      "\tSNR 10 | Final F1: 0.9578\n",
      "\tSNR 15 | Final F1: 0.9683\n",
      "\tSNR 20 | Final F1: 0.9717\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "Training model: LWM - Channel Embeddings\n",
      "\tRatio 0.0010 | Training Samples: 10 | Final F1: 0.9377\n",
      "\tRatio 0.0100 | Training Samples: 104 | Final F1: 0.9376\n",
      "\tRatio 0.0500 | Training Samples: 522 | Final F1: 0.9684\n",
      "\tRatio 0.1000 | Training Samples: 1044 | Final F1: 0.9727\n",
      "\tRatio 0.2500 | Training Samples: 2610 | Final F1: 0.9871\n",
      "\tRatio 0.5000 | Training Samples: 5220 | Final F1: 0.9895\n",
      "\tRatio 0.8000 | Training Samples: 8352 | Final F1: 0.9962\n",
      "\tMFLOPs: 11.009794 | Params_M: 6.831394 | Encoder Latency: 13.9810 | Head Latency: 1.4539\n",
      "\tSNR -20 | Final F1: 0.6461\n",
      "\tSNR -15 | Final F1: 0.7179\n",
      "\tSNR -10 | Final F1: 0.7839\n",
      "\tSNR -5 | Final F1: 0.8312\n",
      "\tSNR 0 | Final F1: 0.9233\n",
      "\tSNR 5 | Final F1: 0.9780\n",
      "\tSNR 10 | Final F1: 0.9895\n",
      "\tSNR 15 | Final F1: 0.9943\n",
      "\tSNR 20 | Final F1: 0.9952\n",
      "\tRunning t-SNE Analysis...\n",
      "\tt-SNE Analysis Complete\n",
      "   t-SNE data saved to: ../results/LoS_NLoS_Classification/city_6_miami/2026-02-04_12-53-16/tsne_comparison_data.csv\n"
     ]
    }
   ],
   "source": [
    "from thesis.los_nlos import run_los_nlos_task\n",
    "\n",
    "experiments = [\"raw_model\", \"enhanced_raw_model\",\n",
    "               \"ae_1_16\", \"ae_1_32\",\n",
    "               \"lwm_cls\", \"lwm_cls_partial_ft\",\n",
    "               \"lwm_cls_full_ft\", \"lwm_channel_emb\"]\n",
    "\n",
    "experiments_configs = []\n",
    "for experiment in experiments:\n",
    "    config = ModelConfig.load_json(f\"../experiments/LoS_NLoS_Classification/{experiment}.json\")\n",
    "    experiments_configs.append(config)\n",
    "\n",
    "task_config = TaskConfig.load_json(\"../experiments/LoS_NLoS_Classification/task_config_miami.json\")\n",
    "\n",
    "run_los_nlos_task(experiments_configs, task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13080df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Task: Beam_Selection\n",
      "Results will be saved to: ./results/Beam_Selection/city_6_miami/2026-02-04_12-15-59\n",
      "Loading Data for city_6_miami...\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading ray-tracing: 100%|██████████| 42984/42984 [00:00<00:00, 183845.75it/s]\n",
      "Generating channels: 100%|██████████| 42984/42984 [00:05<00:00, 7733.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValid Users:    10441\n",
      "Training model: LWM - Channel Embeddings | Configuration with 16 beams.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Beam Search (16): 100%|██████████| 10441/10441 [00:00<00:00, 26379.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRatio 0.0800 | Training Samples: 335 | Final F1: 0.7834\n",
      "\tRatio 0.1600 | Training Samples: 670 | Final F1: 0.7975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m     experiments_configs.append(config)\n\u001b[32m     15\u001b[39m task_config = TaskConfig.load_json(\u001b[33m\"\u001b[39m\u001b[33mexperiments/Beam_Selection/task_config_miami.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mrun_beam_selection_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiments_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/src/thesis/beam_selection.py:266\u001b[39m, in \u001b[36mrun_beam_selection_task\u001b[39m\u001b[34m(experiment_configs, task_config)\u001b[39m\n\u001b[32m    263\u001b[39m train_dl, val_dl = create_dataloaders(X_all, y_all, train_ratio=ratio, seed=\u001b[32m42\u001b[39m)\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# A. Build Fresh Model - This needs some adjustment\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m model = \u001b[43mbuild_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;66;03m# B. Train - This needs some adjustment\u001b[39;00m\n\u001b[32m    269\u001b[39m final_f1, model, _, total_train_time = train_downstream(model, train_dl, val_dl, task_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/src/thesis/downstream_models.py:209\u001b[39m, in \u001b[36mbuild_model_from_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m config.encoder_type == \u001b[33m\"\u001b[39m\u001b[33mLWM\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    208\u001b[39m     tokenizer = Tokenizer(patch_rows=\u001b[32m4\u001b[39m, patch_cols=\u001b[32m4\u001b[39m, scale_factor=\u001b[32m1e0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     encoder = \u001b[43mlwm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# 3. Grad Management\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/src/thesis/lwm_model.py:132\u001b[39m, in \u001b[36mlwm.from_pretrained\u001b[39m\u001b[34m(cls, ckpt_name, device)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, ckpt_name=\u001b[33m'\u001b[39m\u001b[33mmodel_weights.pth\u001b[39m\u001b[33m'\u001b[39m, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    131\u001b[39m     model = \u001b[38;5;28mcls\u001b[39m().to(device)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     state_dict = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Robust Key Cleaning\u001b[39;00m\n\u001b[32m    135\u001b[39m     new_state_dict = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/torch/serialization.py:1516\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1518\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1519\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1521\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1524\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/torch/serialization.py:2114\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2113\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2114\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2115\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2117\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/torch/_weights_only_unpickler.py:532\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    525\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ):\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    530\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    534\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/torch/serialization.py:2077\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2075\u001b[39m     typed_storage = loaded_storages[key]\n\u001b[32m   2076\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2077\u001b[39m     nbytes = numel * \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_element_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2078\u001b[39m     typed_storage = load_tensor(\n\u001b[32m   2079\u001b[39m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[32m   2080\u001b[39m     )\n\u001b[32m   2082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/venv/lib/python3.12/site-packages/torch/_utils.py:882\u001b[39m, in \u001b[36m_element_size\u001b[39m\u001b[34m(dtype)\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.finfo(dtype).bits >> \u001b[32m2\u001b[39m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype.is_floating_point:\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m.bits >> \u001b[32m3\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype == torch.bool:\n\u001b[32m    884\u001b[39m     \u001b[38;5;66;03m# NOTE: torch.bool is not supported in torch.iinfo()\u001b[39;00m\n\u001b[32m    885\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from thesis.beam_selection import run_beam_selection_task\n",
    "\n",
    "experiments = [#\"raw_model\",\n",
    "               #\"ae_1_16\", \"ae_1_32\",\n",
    "               #\"lwm_cls\", \"lwm_cls_partial_ft\",\n",
    "               #\"lwm_cls_full_ft\",\n",
    "                \"lwm_channel_emb\"]\n",
    "\n",
    "experiments_configs = []\n",
    "for experiment in experiments:\n",
    "    config = ModelConfig.load_json(f\"experiments/Beam_Selection/{experiment}.json\")\n",
    "    experiments_configs.append(config)\n",
    "\n",
    "task_config = TaskConfig.load_json(\"experiments/Beam_Selection/task_config_miami.json\")\n",
    "\n",
    "run_beam_selection_task(experiments_configs, task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bcb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
